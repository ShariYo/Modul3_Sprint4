{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import functions_sandbox as sand\n",
    "importlib.reload(sand)\n",
    "import pickle\n",
    "import time\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    KFold,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedKFold\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = r\"D:\\IT_projects\\Turing_Colledge\\train_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>name_contract_type</th>\n",
       "      <th>code_gender</th>\n",
       "      <th>flag_own_car</th>\n",
       "      <th>flag_own_realty</th>\n",
       "      <th>cnt_children</th>\n",
       "      <th>amt_annuity</th>\n",
       "      <th>name_type_suite</th>\n",
       "      <th>name_income_type</th>\n",
       "      <th>name_education_type</th>\n",
       "      <th>...</th>\n",
       "      <th>amt_req_credit_bureau_hour</th>\n",
       "      <th>amt_req_credit_bureau_day</th>\n",
       "      <th>amt_req_credit_bureau_week</th>\n",
       "      <th>amt_req_credit_bureau_mon</th>\n",
       "      <th>amt_req_credit_bureau_qrt</th>\n",
       "      <th>amt_req_credit_bureau_year</th>\n",
       "      <th>active_credit_count</th>\n",
       "      <th>total_debt_all</th>\n",
       "      <th>prol_credits</th>\n",
       "      <th>credit_to_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>10.114619</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.101238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>10.482892</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.756262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>8.817446</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target name_contract_type code_gender flag_own_car flag_own_realty  \\\n",
       "0       1         Cash loans           M            N               Y   \n",
       "1       0         Cash loans           F            N               N   \n",
       "2       0    Revolving loans           M            Y               Y   \n",
       "\n",
       "   cnt_children  amt_annuity name_type_suite name_income_type  \\\n",
       "0             0    10.114619   Unaccompanied          Working   \n",
       "1             0    10.482892          Family    State servant   \n",
       "2             0     8.817446   Unaccompanied          Working   \n",
       "\n",
       "             name_education_type  ... amt_req_credit_bureau_hour  \\\n",
       "0  Secondary / secondary special  ...                          0   \n",
       "1               Higher education  ...                          0   \n",
       "2  Secondary / secondary special  ...                          0   \n",
       "\n",
       "  amt_req_credit_bureau_day  amt_req_credit_bureau_week  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "\n",
       "   amt_req_credit_bureau_mon  amt_req_credit_bureau_qrt  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "\n",
       "   amt_req_credit_bureau_year  active_credit_count  total_debt_all  \\\n",
       "0                           1             1.098612        positive   \n",
       "1                           0             0.693147               0   \n",
       "2                           0             0.000000               0   \n",
       "\n",
       "   prol_credits  credit_to_income  \n",
       "0           0.0          1.101238  \n",
       "1           0.0          1.756262  \n",
       "2           0.0          1.098612  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path_train)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have our clean prepared data, we can split it into three parts:  \n",
    "data train, data validation and data test. Data validation will have 15% of  \n",
    "whole dataset as well as data test. 70% of dataset will be to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=\"target\", axis=1)\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_remain, y_remain, test_size=0.5, stratify=y_remain, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also prepare my preprocessor for pipeline which will be used in whole  \n",
    "model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_selector = selector(dtype_include=np.number)\n",
    "cat_selector = selector(dtype_include=[object, \"category\"])\n",
    "numeric = num_selector(X)\n",
    "categoric = cat_selector(X)\n",
    "\n",
    "cat_preprocessor = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    ")\n",
    "\n",
    "num_preprocessor = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", cat_preprocessor, categoric),\n",
    "        (\"numerical\", num_preprocessor, numeric)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part we will select 5 models to work with:  \n",
    "KNN, Logistic Regression, Ridge Classifier, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "results = []\n",
    "\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(solver=\"saga\", max_iter=100, class_weight=\"balanced\"),\n",
    "    \"Ridge Classifier\": RidgeClassifier(solver=\"lsqr\", class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_jobs=6, n_estimators=50, class_weight=\"balanced\"),\n",
    "    \"XGBoost\": XGBClassifier(tree_method=\"hist\", n_jobs=6),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    t_start = time.time()\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "    score = cross_validate(pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "    _ = pipeline.fit(X_train, y_train)\n",
    "    target_predicted = pipeline.predict(X_test)\n",
    "\n",
    "    test_score = pipeline.score(X_val, y_val)\n",
    "    cv_mean = round(score['test_score'].mean(), 3)\n",
    "    cv_std = score['test_score'].std()\n",
    "    precision, recall, f1 = sand.model_result_calc(y_test, target_predicted, pos_label=0)\n",
    "    model_time = round((time.time() - t_start) / 60, 2)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\":model_name,\n",
    "        \"Test_score\":test_score,\n",
    "        \"cv_score_mean\":cv_mean,\n",
    "        \"cv_std\":cv_std,\n",
    "        \"precision\":precision,\n",
    "        \"recall\":recall,\n",
    "        \"f1\":f1,\n",
    "        \"model_time\":model_time\n",
    "    })\n",
    "\n",
    "stop = round((time.time() - start) / 60, 2)\n",
    "print(f\"Total time to complete: {stop} minutes\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: KNN\n",
      "Score: 0.9138090824837812\n",
      "CV score: 0.914 +- 0.0003092010317753735\n",
      "Precision score: 0.92\n",
      "Recall score: 0.99\n",
      "F1 score: 0.95\n",
      "None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: Logistic Regression\n",
      "Score: 0.9194998617953596\n",
      "CV score: 0.919 +- 0.0002631536616727057\n",
      "Precision score: 0.92\n",
      "Recall score: 1.00\n",
      "F1 score: 0.96\n",
      "None\n",
      "\n",
      "Model name: Random Forest\n",
      "Score: 0.9194998617953596\n",
      "CV score: 0.919 +- 5.9537897520459764e-05\n",
      "Precision score: 0.92\n",
      "Recall score: 1.00\n",
      "F1 score: 0.96\n",
      "None\n",
      "\n",
      "Model name: XGBoost\n",
      "Score: 0.919337268100743\n",
      "CV score: 0.919 +- 0.00026733269073546504\n",
      "Precision score: 0.92\n",
      "Recall score: 1.00\n",
      "F1 score: 0.96\n",
      "None\n",
      "\n",
      "Total time to complete: 14.78 minutes\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "\n",
    "# results = []\n",
    "\n",
    "# models = {\n",
    "#     \"KNN\": KNeighborsClassifier(),\n",
    "#     \"Logistic Regression\": LogisticRegression(solver=\"saga\", max_iter=100),\n",
    "#     \"Ridge Classifier\": RidgeClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_jobs=6, n_estimators=50),\n",
    "#     \"XGBoost\": XGBClassifier(tree_method=\"hist\", n_jobs=6),\n",
    "# }\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     pipeline = make_pipeline(preprocessor, model)\n",
    "\n",
    "#     score = cross_validate(pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "#     _ = pipeline.fit(X_train, y_train)\n",
    "#     target_predicted = pipeline.predict(X_test)\n",
    "\n",
    "#     print(f\"Model name: {model_name}\")\n",
    "#     print(f\"Score: {pipeline.score(X_val, y_val)}\")\n",
    "#     print(f\"CV score: {score['test_score'].mean():.3f} +- {score['test_score'].std()}\")\n",
    "#     print(f\"{sand.model_result_calc(y_test, target_predicted, pos_label=0)}\\n\")\n",
    "# stop = round((time.time() - start) / 60, 2)\n",
    "# print(f\"Total time to complete: {stop} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the high overall performance, especially in recall and F1 score, RandomForest  \n",
    "is the best choice for this dataset. It offers the best balance of precision,  \n",
    "recall, and generalization ability as raw model for further updates.  \n",
    "Hyperparameters will be added to increase overall model's performance and  \n",
    "decision assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 255, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1104, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 750, in fit_transform\n",
      "    return self._hstack(list(Xs))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 865, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py\", line 359, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 275. MiB for an array with shape (196806, 183) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 255, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1104, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 750, in fit_transform\n",
      "    return self._hstack(list(Xs))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 865, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py\", line 359, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 276. MiB for an array with shape (196806, 184) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 329, in fit\n",
      "    Xt, yt = self._fit(X, y, routed_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 255, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 1104, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 750, in fit_transform\n",
      "    return self._hstack(list(Xs))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 865, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\shape_base.py\", line 359, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 275. MiB for an array with shape (196807, 183) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Vykintas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.63061366 0.62995934 0.66469387 0.62436169 0.64028815\n",
      " 0.6660556  0.66996198 0.65573909 0.62005307 0.63691843 0.6341745\n",
      " 0.63680456 0.7119606  0.54008953 0.56339683 0.66078747 0.59976917\n",
      " 0.70770464 0.65695019]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForest: {'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__min_samples_split': 20, 'randomforestclassifier__min_samples_leaf': 20, 'randomforestclassifier__max_leaf_nodes': 1000, 'randomforestclassifier__max_depth': 10, 'randomforestclassifier__class_weight': 'balanced'}\n",
      "Total time to complete: 31.86 minutes\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "pipeline = make_pipeline(preprocessor, rf_model)\n",
    "\n",
    "rf_hparams = {\n",
    "    \"randomforestclassifier__max_depth\": [2, 5, 10, 20],\n",
    "    \"randomforestclassifier__n_estimators\": [1, 10, 25, 50, 100],\n",
    "    \"randomforestclassifier__max_leaf_nodes\": [10, 100, 1000],\n",
    "    \"randomforestclassifier__min_samples_split\": [10, 20, 50, 100],\n",
    "    \"randomforestclassifier__min_samples_leaf\": [5, 10, 20, 50, 100],\n",
    "    \"randomforestclassifier__class_weight\": [\"balanced\"],\n",
    "}\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "start = time.time()\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=rf_hparams,\n",
    "    n_iter=20,\n",
    "    cv=stratified_kfold,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=6,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters for RandomForest: {random_search.best_params_}\")\n",
    "stop = round((time.time() - start) / 60, 2)\n",
    "print(f\"Total time to complete: {stop} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have updated our RandomForestClassifier model with hyperparameters and using  \n",
    "randomized search technique found best parameters for the model:  \n",
    "- max depth: 20  \n",
    "- n estimators: 50  \n",
    "- min samples split: 100  \n",
    "- min samples leaf: 50  \n",
    "- max leaf nodes: 1000  \n",
    "- class weight: balanced  \n",
    "Now we can check the accuracy of the model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated accuracy: 0.7090\n"
     ]
    }
   ],
   "source": [
    "# RandomForest accuracy\n",
    "best_est = random_search.best_estimator_\n",
    "pred_best = best_est.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, pred_best)\n",
    "print(f\"Calculated accuracy: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got decent result of ~0.74.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some insights of trained model through classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mX_test\u001b[49m, pred_best))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(X_test, pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate imbalanced performance between classes, with overall  \n",
    "accuracy at 0.74. For class 0, the model achieves strong metrics: precision  \n",
    "of 0.95, recall of 0.75, and an F1-score of 0.84, reflecting reliable predictions  \n",
    "for the majority class. In contrast, class 1 metrics are weak, with precision  \n",
    "at 0.17, recall at 0.59, and an F1-score of 0.27, highlighting high false  \n",
    "positives and limited precision.  \n",
    "The macro average F1-score of 0.55 shows disparities in performance across  \n",
    "classes, while the weighted average F1-score of 0.80 is skewed by the  \n",
    "dominance of class 0. These results suggest the model heavily favors the  \n",
    "majority class and struggles with the minority class. These results were shows  \n",
    "that even models hyperparameter \"class weight\" didn't have strong positive  \n",
    "influence to the final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the results I wanted to see features importance to the model. Some  \n",
    "features might be removed if importance is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>standard_scaler__ext_source_2</td>\n",
       "      <td>0.211414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>standard_scaler__ext_source_3</td>\n",
       "      <td>0.201333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>standard_scaler__client_age</td>\n",
       "      <td>0.048033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>standard_scaler__years_employed</td>\n",
       "      <td>0.046992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>standard_scaler__days_last_phone_change</td>\n",
       "      <td>0.036414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Feature  Importance\n",
       "149            standard_scaler__ext_source_2    0.211414\n",
       "150            standard_scaler__ext_source_3    0.201333\n",
       "130              standard_scaler__client_age    0.048033\n",
       "131          standard_scaler__years_employed    0.046992\n",
       "154  standard_scaler__days_last_phone_change    0.036414"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = random_search.best_estimator_.named_steps['randomforestclassifier']\n",
    "\n",
    "importances = best_rf_model.feature_importances_\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importances_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herein we can see few main features with the highest importance to the model.  \n",
    "At the EDA part, I thought that flag_document features might be not that important,  \n",
    "so I checked importance specially targeting only flag_document importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>standard_scaler__flag_document_3</td>\n",
       "      <td>0.011713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>standard_scaler__flag_document_6</td>\n",
       "      <td>0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>standard_scaler__flag_document_8</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>standard_scaler__flag_document_16</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>standard_scaler__flag_document_5</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>standard_scaler__flag_document_18</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>standard_scaler__flag_document_13</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>standard_scaler__flag_document_11</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>standard_scaler__flag_document_14</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>standard_scaler__flag_document_9</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>standard_scaler__flag_document_15</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>standard_scaler__flag_document_20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>standard_scaler__flag_document_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>standard_scaler__flag_document_17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>standard_scaler__flag_document_19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>standard_scaler__flag_document_21</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>standard_scaler__flag_document_10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>standard_scaler__flag_document_7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>standard_scaler__flag_document_4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>standard_scaler__flag_document_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature  Importance\n",
       "156   standard_scaler__flag_document_3    0.011713\n",
       "159   standard_scaler__flag_document_6    0.001803\n",
       "161   standard_scaler__flag_document_8    0.001538\n",
       "169  standard_scaler__flag_document_16    0.000561\n",
       "158   standard_scaler__flag_document_5    0.000286\n",
       "171  standard_scaler__flag_document_18    0.000222\n",
       "166  standard_scaler__flag_document_13    0.000157\n",
       "164  standard_scaler__flag_document_11    0.000140\n",
       "167  standard_scaler__flag_document_14    0.000135\n",
       "162   standard_scaler__flag_document_9    0.000045\n",
       "168  standard_scaler__flag_document_15    0.000027\n",
       "173  standard_scaler__flag_document_20    0.000000\n",
       "165  standard_scaler__flag_document_12    0.000000\n",
       "170  standard_scaler__flag_document_17    0.000000\n",
       "172  standard_scaler__flag_document_19    0.000000\n",
       "174  standard_scaler__flag_document_21    0.000000\n",
       "163  standard_scaler__flag_document_10    0.000000\n",
       "160   standard_scaler__flag_document_7    0.000000\n",
       "157   standard_scaler__flag_document_4    0.000000\n",
       "155   standard_scaler__flag_document_2    0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_document = feature_importances_df[\n",
    "    feature_importances_df[\"Feature\"].str.contains(\"flag_document\")\n",
    "]\n",
    "flag_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, flag_documents importance is very low and these could be removed \n",
    "from dataset to increase model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_doc = X_train.columns[X_train.columns.str.contains(\"flag_document\")]\n",
    "X_train_v1 = X_train.drop(columns=flag_doc)\n",
    "# data_test_v1 = data_test.drop(columns=flag_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train_v1, y_train)\n",
    "\n",
    "best_est = random_search.best_estimator_\n",
    "pred_best = best_est.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, pred_best)\n",
    "print(f\"Calculated accuracy: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test = pd.read_csv(\"clean_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = clean_test.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probality of default loan is: [0.58804818]\n",
      "Final prediction is: [ True]\n"
     ]
    }
   ],
   "source": [
    "pred_target = best_est.predict_proba(clean_test.iloc[199:200])[:, 1]\n",
    "prediction = pred_target >= 0.5\n",
    "\n",
    "print(f\"Prediction probality of default loan is: {pred_target}\")\n",
    "print(f\"Final prediction is: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;name_contract_type&#x27;,\n",
       "                                                   &#x27;code_gender&#x27;,\n",
       "                                                   &#x27;flag_own_car&#x27;,\n",
       "                                                   &#x27;flag_own_realty&#x27;,\n",
       "                                                   &#x27;name_type_suite&#x27;,\n",
       "                                                   &#x27;name_income_type&#x27;,\n",
       "                                                   &#x27;name_education_type&#x27;,\n",
       "                                                   &#x27;name_family_status&#x27;,\n",
       "                                                   &#x27;name_housing_type&#x27;,\n",
       "                                                   &#x27;occupation_type&#x27;,\n",
       "                                                   &#x27;weekday_appr_process_start&#x27;,\n",
       "                                                   &#x27;organi...\n",
       "                                                   &#x27;live_city_not_work_city&#x27;,\n",
       "                                                   &#x27;ext_source_2&#x27;,\n",
       "                                                   &#x27;ext_source_3&#x27;,\n",
       "                                                   &#x27;def_30_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;obs_60_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;def_60_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;days_last_phone_change&#x27;,\n",
       "                                                   &#x27;flag_document_2&#x27;, ...])])),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                                        max_leaf_nodes=1000,\n",
       "                                        min_samples_leaf=50,\n",
       "                                        min_samples_split=100,\n",
       "                                        n_estimators=50))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;name_contract_type&#x27;,\n",
       "                                                   &#x27;code_gender&#x27;,\n",
       "                                                   &#x27;flag_own_car&#x27;,\n",
       "                                                   &#x27;flag_own_realty&#x27;,\n",
       "                                                   &#x27;name_type_suite&#x27;,\n",
       "                                                   &#x27;name_income_type&#x27;,\n",
       "                                                   &#x27;name_education_type&#x27;,\n",
       "                                                   &#x27;name_family_status&#x27;,\n",
       "                                                   &#x27;name_housing_type&#x27;,\n",
       "                                                   &#x27;occupation_type&#x27;,\n",
       "                                                   &#x27;weekday_appr_process_start&#x27;,\n",
       "                                                   &#x27;organi...\n",
       "                                                   &#x27;live_city_not_work_city&#x27;,\n",
       "                                                   &#x27;ext_source_2&#x27;,\n",
       "                                                   &#x27;ext_source_3&#x27;,\n",
       "                                                   &#x27;def_30_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;obs_60_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;def_60_cnt_social_circle&#x27;,\n",
       "                                                   &#x27;days_last_phone_change&#x27;,\n",
       "                                                   &#x27;flag_document_2&#x27;, ...])])),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                                        max_leaf_nodes=1000,\n",
       "                                        min_samples_leaf=50,\n",
       "                                        min_samples_split=100,\n",
       "                                        n_estimators=50))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;name_contract_type&#x27;, &#x27;code_gender&#x27;,\n",
       "                                  &#x27;flag_own_car&#x27;, &#x27;flag_own_realty&#x27;,\n",
       "                                  &#x27;name_type_suite&#x27;, &#x27;name_income_type&#x27;,\n",
       "                                  &#x27;name_education_type&#x27;, &#x27;name_family_status&#x27;,\n",
       "                                  &#x27;name_housing_type&#x27;, &#x27;occupation_type&#x27;,\n",
       "                                  &#x27;weekday_appr_process_start&#x27;,\n",
       "                                  &#x27;organization_type&#x27;, &#x27;total_debt_all&#x27;]),\n",
       "                                (&#x27;sta...\n",
       "                                  &#x27;hour_appr_process_start&#x27;,\n",
       "                                  &#x27;reg_region_not_live_region&#x27;,\n",
       "                                  &#x27;reg_region_not_work_region&#x27;,\n",
       "                                  &#x27;live_region_not_work_region&#x27;,\n",
       "                                  &#x27;reg_city_not_live_city&#x27;,\n",
       "                                  &#x27;reg_city_not_work_city&#x27;,\n",
       "                                  &#x27;live_city_not_work_city&#x27;, &#x27;ext_source_2&#x27;,\n",
       "                                  &#x27;ext_source_3&#x27;, &#x27;def_30_cnt_social_circle&#x27;,\n",
       "                                  &#x27;obs_60_cnt_social_circle&#x27;,\n",
       "                                  &#x27;def_60_cnt_social_circle&#x27;,\n",
       "                                  &#x27;days_last_phone_change&#x27;, &#x27;flag_document_2&#x27;, ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;name_contract_type&#x27;, &#x27;code_gender&#x27;, &#x27;flag_own_car&#x27;, &#x27;flag_own_realty&#x27;, &#x27;name_type_suite&#x27;, &#x27;name_income_type&#x27;, &#x27;name_education_type&#x27;, &#x27;name_family_status&#x27;, &#x27;name_housing_type&#x27;, &#x27;occupation_type&#x27;, &#x27;weekday_appr_process_start&#x27;, &#x27;organization_type&#x27;, &#x27;total_debt_all&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sk_id_curr&#x27;, &#x27;cnt_children&#x27;, &#x27;amt_annuity&#x27;, &#x27;region_population_relative&#x27;, &#x27;client_age&#x27;, &#x27;years_employed&#x27;, &#x27;years_registration&#x27;, &#x27;years_id_publish&#x27;, &#x27;flag_mobil&#x27;, &#x27;flag_emp_phone&#x27;, &#x27;flag_work_phone&#x27;, &#x27;flag_cont_mobile&#x27;, &#x27;flag_phone&#x27;, &#x27;flag_email&#x27;, &#x27;cnt_fam_members&#x27;, &#x27;region_rating_client_w_city&#x27;, &#x27;hour_appr_process_start&#x27;, &#x27;reg_region_not_live_region&#x27;, &#x27;reg_region_not_work_region&#x27;, &#x27;live_region_not_work_region&#x27;, &#x27;reg_city_not_live_city&#x27;, &#x27;reg_city_not_work_city&#x27;, &#x27;live_city_not_work_city&#x27;, &#x27;ext_source_2&#x27;, &#x27;ext_source_3&#x27;, &#x27;def_30_cnt_social_circle&#x27;, &#x27;obs_60_cnt_social_circle&#x27;, &#x27;def_60_cnt_social_circle&#x27;, &#x27;days_last_phone_change&#x27;, &#x27;flag_document_2&#x27;, &#x27;flag_document_3&#x27;, &#x27;flag_document_4&#x27;, &#x27;flag_document_5&#x27;, &#x27;flag_document_6&#x27;, &#x27;flag_document_7&#x27;, &#x27;flag_document_8&#x27;, &#x27;flag_document_9&#x27;, &#x27;flag_document_10&#x27;, &#x27;flag_document_11&#x27;, &#x27;flag_document_12&#x27;, &#x27;flag_document_13&#x27;, &#x27;flag_document_14&#x27;, &#x27;flag_document_15&#x27;, &#x27;flag_document_16&#x27;, &#x27;flag_document_17&#x27;, &#x27;flag_document_18&#x27;, &#x27;flag_document_19&#x27;, &#x27;flag_document_20&#x27;, &#x27;flag_document_21&#x27;, &#x27;amt_req_credit_bureau_hour&#x27;, &#x27;amt_req_credit_bureau_day&#x27;, &#x27;amt_req_credit_bureau_week&#x27;, &#x27;amt_req_credit_bureau_mon&#x27;, &#x27;amt_req_credit_bureau_qrt&#x27;, &#x27;amt_req_credit_bureau_year&#x27;, &#x27;active_credit_count&#x27;, &#x27;prol_credits&#x27;, &#x27;credit_to_income&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=20,\n",
       "                       max_leaf_nodes=1000, min_samples_leaf=50,\n",
       "                       min_samples_split=100, n_estimators=50)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['name_contract_type',\n",
       "                                                   'code_gender',\n",
       "                                                   'flag_own_car',\n",
       "                                                   'flag_own_realty',\n",
       "                                                   'name_type_suite',\n",
       "                                                   'name_income_type',\n",
       "                                                   'name_education_type',\n",
       "                                                   'name_family_status',\n",
       "                                                   'name_housing_type',\n",
       "                                                   'occupation_type',\n",
       "                                                   'weekday_appr_process_start',\n",
       "                                                   'organi...\n",
       "                                                   'live_city_not_work_city',\n",
       "                                                   'ext_source_2',\n",
       "                                                   'ext_source_3',\n",
       "                                                   'def_30_cnt_social_circle',\n",
       "                                                   'obs_60_cnt_social_circle',\n",
       "                                                   'def_60_cnt_social_circle',\n",
       "                                                   'days_last_phone_change',\n",
       "                                                   'flag_document_2', ...])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                                        max_leaf_nodes=1000,\n",
       "                                        min_samples_leaf=50,\n",
       "                                        min_samples_split=100,\n",
       "                                        n_estimators=50))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = best_est\n",
    "model.fit(X_train_v1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"model.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
